
** Package description:

This package is for extracting and sorting spike data from the explog
and pcm data generated by SABER.

saber generates pcm_seq2 files with raw data and an explog file that
tells what went on during each episode of the acquisition. For multi-
channel acquisition there is a pcm_seq2 file for each channel. In each
episode (i.e. rtrig event in saber, generally one per stimulus) the
data from each channel is stored in a separate entry in the associated
pcm_seq2 file.

** Requirements:

Python version 2.5 or higher; numpy version >=1.3 (for numerics);
scipy version >=0.5 (for FFT and linear algebra); and arf >=1.0.0, for 
data IO.

Optional: matplotlib >= 0.90 is used by spike_view to plot spike
statistics and waveforms.  If this isn't installed, that script won't run.

** Installation:

In the mspikes directory, run python setup.py install

** Copyright/Licence

All code in this package Copyright (C) Dan Meliza 2006-2009
(dmeliza@uchicago.edu)

Free for use under Creative Commons Attribution-Noncommercial-Share
Alike 3.0 United States License
(http://creativecommons.org/licenses/by-nc-sa/3.0/us/)

** Usage:

First, the raw saber data need to be converted to ARF format.  During
this process the data is annotated with metadata found in the saber
explog file.  The 'arfxplog' program that ships with arf is designed to
convert a saber experiment to ARf format:

$ arfxplog -v -a <animal> -e <experimenter> -T EXTRAC_HP -s <explog>

Giving arfxplog the '-s' option causes it to split the data into files
corresponding to recording site (pen/site commands in saber).
IMPORTANT: specify the data type as EXTRAC_HP if you want to see it in
mspike_view.

Second, inspect the data to determine which episodes and channels are
likely to contain single- or multiple-unit activity.  For recordings
in which the animal is awake it is usually desirable to exclude
episodes where it moved.  Single events can usually be sorted out, but
prolonged wiggling generates big clusters of noise that can
dramatically increase the RMS of the signal. Plot the RMS for each
episode using the following command:

$ mspike_view --stats <site.arf>

The bad episodes can be excluded at later stages based on RMS or
time. The 'mspike_view' program can also be used to view the raw spike
waveforms and determine an appropriate threshold for the window
discriminator. It usually makes sense to set the threshold in terms of
RMS units above the mean, since the DC offset and RMS noise level can
shift over the course of acquisition.  The threshold can usually be
set fairly low (around 4.5x RMS) because any single unit worth the
name will cluster out from the noise. Use the following command to
examine waveforms (restricting to channels of interest with the chan
argument):
   
$ mspike_view [--chan=<chan1>,<chan2>,...] <site.arf>

IMPORTANT NOTE: Channels are numbered starting from 0. Multiple
channels must be specified as a comma-separated list.

Third, extract spike times and, optionally, spike waveforms.  For
multi-unit activity or for extremely well isolated units, simple
threshold detection is sufficient.  To detect spikes and store the
event times in the ARF file, use the following command:

$ mspike_extract --simple [--chan=<c1>,<c2>,...] -r <thresh> [OPTIONS] <site.arf>

However, to isolate single units from noise and other units, it is
necessary to extract the waveforms and compute one or more features of
the spike waveforms.  Mspikes uses principal components as well as
several direct measures of spike shape.  The following command will
extract spike waveforms and measure features.

$ mspike_extract [--chan=<c1>,<c2>,...] -r <thresh> [OPTIONS] <site.arf>

This command will export data in a format readable by KlustaKwik (for
automated spike-sorting) and Klusters (for manual cluster cutting).
We recommend using KlustaKwik followed by Klusters to check clusters and
adjust as needed.  To automatically call KlustaKwik on the output of
mspike_extract, add the --kkwik flag.

Finally, collate events based on unit, episode, and stimulus with the
mspike_group tool:

$ mspike_group -a -t <site.arf>

The '-a' flag tells mspike_group to add event data to the original arf
file, grouped by unit and entry.  The '-t' flag tells it to further
organize the event data by stimulus, and output multi-repeat toe_lis
files for each stimulus.  Both flags are optional.  Additional options
are available to restrict the script to specific units, stimuli, and
epidodes.

